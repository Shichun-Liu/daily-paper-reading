[[RL基础]]
[[RLHF]]
[[Q-star]]


## 思考
1. 我们不讨论哲学问题，那么人类能否造出比自己更强大的物种？
- 强大这个概念太宽泛，可以先聚焦于某一个具体的能力
	- 能力分为rule-based和非rule-based；
	- 计算器本身就是一个基于规则的工具，计算能力强于人类；
	- 围棋的游戏规则是明确的，但是下围棋的最优策略并没有明确的规则，只能从数据+搜索中得到下一步的最优解；AI在下围棋上面的能力强于人类，且不需要利用人类经验的监督而是靠自我博弈；
	- 下围棋的步骤可以认为是一种决策（搜索策略），说明AI可以完成做决策这一件事情且不弱于人类；但只局限于明确的单一场景，AI可以直接计算得到action-value；
	- 复杂场景下，搜索过程如何优化？
- 物种的概念不明确，可以先聚焦于某个单一功能的工具
	- 复杂工具可以视为多个单一工具的复合；多个工具之间的协作由决策器完成；

2. 语言模型的局限性，语言模型能否真正做推理还是仅仅模式匹配？
	- 人类是如何完成数学推理和创新的？传统的机器学习+数学推导是如何进行的？ 

3. 在哪些领域、哪些任务上，AI的准确性和一致性比人类更好，那么这些任务上基于先验规则的RLAIF在规则上可以遵守地比人类更好。
- 是否要考虑多样性的情况？diversity在何时发挥作用？