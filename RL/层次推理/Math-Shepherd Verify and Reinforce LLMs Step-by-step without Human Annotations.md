---
tags:
  - reasonging
  - math
date: 2023-12-28
---

## 要点
- 提出MATH-SHEPHERD，一个自动的**过程奖励模型**，用于评价数学问题解法的每一步，打破了过程奖励模型训练中对昂贵人工标注的依赖。
- MATH-SHEPHERD通过自动构建的过程化监督数据进行训练，利用补全模型从中间步骤生成多个后续推理路径，并验证最终答案是否与标准答案匹配，能推导出更多正确答案的步骤被赋予更高的分数。
- MATH-SHEPHERD在数学问题**验证**和**强化学习**两方面进行评估，前者通过对LLM生成的多个候选解进行重新排序 **reranking**，后者通过提供逐步奖励 **PRM**。
- 在GSM8K和MATH基准测试中，实验结果显示，与7B到70B的LLM结合使用时，MATH-SHEPHERD始终优于结果奖励模型和自洽性基准，逐步强化学习也显著提高了LLM的性能。
- 分析显示了自动标注的质量、模型大小的影响以及低资源环境下的优势，结果证明了自动过程监督的有效性。

动机：解决大型语言模型在复杂多步数学推理问题上的挑战，探索自动化过程监督对语言模型进化的潜力。  



