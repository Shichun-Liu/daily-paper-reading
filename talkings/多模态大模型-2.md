 2023-12-19
 
## 图像生成
### SEED-LLaMa

![image.png|700](https://raw.githubusercontent.com/Shichun-Liu/images-on-picgo/main/pics/20231219134101.png)

- 重点是SD-UNet部分作为生成模型；
- 能够做图像生成任务，也可以做文本生成任务；

#### 训练过程
**1. SEED预训练阶段**

![image.png|600](https://raw.githubusercontent.com/Shichun-Liu/images-on-picgo/main/pics/20231219134643.png)

- 通过对齐中间步骤的各种表示，能够对于结果的质量得到一个较好的保证；
	- 使用Q-former得到特征表示（长度为32），使用最后一个token与text-embedding进行对比学习；
- **Codebook：对于特征的连续表示进行离散化**（映射到一个**固定词表**，固定词表的大小同样设定为32）；
	- 通过最近邻匹配，把causal embedding分别匹配最接近的词表中的语句，得到对应的下标序列；
	- 特征在32个token中分布并不均匀，存在可优化的地方；
	- 表示的离散值（5，2，...，1，7）是对应的embedding向量的下标，对应的表示空间是连续的；
	- 通过SD decoder进行生成，最后发现离散表示的recall也可以达到90%，效果不错；
- SEED作用：**输入一个图片，得到一个图像的离散特征表示**；相当于是作为一个图像的tokenizer；

**2. LLM pretraining（Full-FT）**

![image.png](https://raw.githubusercontent.com/Shichun-Liu/images-on-picgo/main/pics/20231219135255.png)

- input：一张图片+一段问题，相当于上述过程中IMG到bloom的部分；N+5表示的拓展词表部分（原先vocab的大小为N）；
- output：右侧的IMG输出以及decode出来的图像，用实际的图像作为监督信号；
- 32个特征的排列组合可以表示大部分图像语义；
	- 一张图片压缩成**几个**token是“无损”的压缩？32个是否足够？

**3. SFT（LoRA）**
在一系列任务上微调。

![image.png|500](https://raw.githubusercontent.com/Shichun-Liu/images-on-picgo/main/pics/20231219141246.png)

#### 实验
- 图像的离散化特征近似会造成一定的精度损失，但在可接受范围之内；

![image.png|625](https://raw.githubusercontent.com/Shichun-Liu/images-on-picgo/main/pics/20231219141556.png)


## 视频生成
主要内容

![image.png|325](https://raw.githubusercontent.com/Shichun-Liu/images-on-picgo/main/pics/20231219144820.png)

### 视频模型加入
**Flamingo**

![image.png|500](https://raw.githubusercontent.com/Shichun-Liu/images-on-picgo/main/pics/20231219145129.png)

fewshot形式；

**Next-GPT**

**OneLLM**
[OneLLM：统一的框架将八种模态与语言对齐-(代码已开源) - 知乎](https://zhuanlan.zhihu.com/p/671021059)
[OneLLM：对齐所有模态的框架！-腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/2369711)

**Video-LLaMa**
比较简单的工作；